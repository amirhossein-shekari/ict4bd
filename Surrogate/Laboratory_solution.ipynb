{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Besos Work Flow from idf to surrogate desgin optimization\n",
    "\n",
    "\n",
    "In this laboratory you will go over some of the basic work flow to create a a surrogate design optimization model from an EnergyPlus simulation. You will train a surrogate model network to find optimal design parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#!pip install besos --user\n",
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from besos import eppy_funcs as ef\n",
    "from besos import sampling\n",
    "from besos.evaluator import EvaluatorEP,EvaluatorGeneric\n",
    "from besos.parameters import RangeParameter, FieldSelector, FilterSelector, Parameter, expand_plist, wwr, CategoryParameter, GenericSelector\n",
    "from besos.problem import EPProblem, Problem\n",
    "from besos import eppy_funcs as ef, sampling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "from seaborn import pairplot\n",
    "from plotly import express as px\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Laboratory you will have to perform a surrogate optimization of a sample residential building unit. The considered unit is composed by a typical flat of a multi-storey building. Its internal organisation and definition is in line with suggested residential building typologies included in well-known architectural technical manuals  The considered building is composed by two units for floor, while a single unit is simulated for this chapter. The simulated spaces are considered to be at an intermediate floor with an upper floor and lower floor working at the same temperature (adiabatic). Similarly, the simulated unit is touching a specular one: confining walls are also assumed as adiabatic. Upper-floor balconies are included to consider shading effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](image/building_lab.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Building \n",
    "\n",
    "The building is defined by the Information Data File (IDF) or using the new EnergyPlus format (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the IDF file\n",
    "building = ef.get_building('lab_building.idf')\n",
    "building.view_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true"
   },
   "source": [
    "## Evaluator\n",
    "## Set up the inputs and outputs of your exploration\n",
    "\n",
    "- what properties of the building will we be changing?\n",
    "- what are some of the performance metrics of the building that we want to explore?\n",
    "- what external weather conditions is the building experiencing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](image/setting_up_the_evaluator.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Display Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The weather conditions are specified in the EnergyPlus Weather File (EWP) file. The properties we will change in the building will be defined in the parameter space. In the objectives we will specify the what output performance metrics we wish to extract such that we can explore them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epw import epw\n",
    "meteo = epw()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epw_file='PARIS_FR-hour.epw'\n",
    "meteo.read(epw_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo.dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define The Problem\n",
    "\n",
    "1. Define the parameters and your objectives you whant to change\n",
    "2. Create Selectors for getting the paramters fileds in the model\n",
    "3. Describe the parameter variation\n",
    "4. Define your problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building.idfobjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roof_ins = FieldSelector(class_name='Material',\n",
    "                         object_name='MW Glass Wool (rolls)_.1445',\n",
    "                         field_name='Thickness')\n",
    "wall_ins = FieldSelector(class_name='Material', \n",
    "                         object_name='EPS Expanded Polystyrene (Heavyweight)_.1', \n",
    "                         field_name='Thickness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wall_range = RangeParameter(min_val=0.1,max_val=0.5)\n",
    "roof_range = RangeParameter(min_val=0.1,max_val=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine this with the `Selector` above to get a `Parameter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insulation_param = [Parameter(selector=wall_ins,\n",
    "                                 value_descriptor=wall_range ,\n",
    "                                 name='Wall Insulation'),\n",
    "                   Parameter(selector=roof_ins,\n",
    "                                 value_descriptor=roof_range ,\n",
    "                                 name='Roof Insulation')]\n",
    "print(insulation_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[window for window in building.idfobjects['FENESTRATIONSURFACE:DETAILED'] if window.Surface_Type=='Window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = FieldSelector(class_name='FenestrationSurface:Detailed', \n",
    "                        object_name='*',\n",
    "                        field_name='Construction Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows.get_objects(building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection of windows parameters\n",
    "win_arr = ['single_glazing','double_glazing','triple_glazing']\n",
    "windowsTypes = CategoryParameter(win_arr)\n",
    "\n",
    "windowsParameters = []\n",
    "\n",
    "for fenestration in building.idfobjects[\"FenestrationSurface:Detailed\"]:\n",
    "     if fenestration.obj[2] == \"Window\":\n",
    "        sel = FieldSelector(class_name ='FenestrationSurface:Detailed', \n",
    "                            object_name = fenestration.Name, \n",
    "                            field_name='Construction Name' )\n",
    "        windowsParameters.append(Parameter(selector=sel, \n",
    "                                           value_descriptors = windowsTypes, \n",
    "                                           name='Windows types'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowsParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACH parameters selection\n",
    "ventAchRange = RangeParameter(min_val = 0.0, max_val=6.0)\n",
    "\n",
    "ventilationAchParam = []\n",
    "\n",
    "\n",
    "ventACH_sel = FieldSelector(class_name = 'ZoneVentilation:DesignFlowRate', \n",
    "                    object_name = '*', \n",
    "                    field_name = 'Air Changes per Hour')\n",
    "ventilationAchParam.append(Parameter(selector=ventACH_sel, \n",
    "                                     value_descriptors=ventAchRange, \n",
    "                                     name='Ventilation ACH'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilationAchParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights_selector = FieldSelector(class_name='Lights', object_name='*', field_name='Watts per Zone Floor Area')\n",
    "lights_range = RangeParameter(min_val=8,max_val=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lights_param =     Parameter(\n",
    "        lights_selector,\n",
    "        value_descriptor=lights_range ,\n",
    "        name=\"Lights Watts/Area\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[shadeControl for shadeControl in building.idfobjects[\"WINDOWSHADINGCONTROL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TempShadingRange = RangeParameter(min_val = 18, max_val=30)\n",
    "RadShadingRange = RangeParameter(min_val = 80, max_val=300)\n",
    "\n",
    "setpointParams = []\n",
    "shade_setpoint_sel = FieldSelector(class_name ='WindowShadingControl', \n",
    "                    object_name = '*', \n",
    "                    field_name='Setpoint' )\n",
    "shade_setpoint2_sel = FieldSelector(class_name ='WindowShadingControl', \n",
    "                     object_name = '*', \n",
    "                     field_name='Setpoint 2' )\n",
    "setpointParams.append(Parameter(selector=shade_setpoint_sel, value_descriptor = TempShadingRange, name='Temp Setpoint shading'))\n",
    "setpointParams.append(Parameter(selector=shade_setpoint2_sel, value_descriptor = RadShadingRange, name='Rad Setpoint shading'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = insulation_param + windowsParameters + [lights_param] + ventilationAchParam + setpointParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.021458,
     "end_time": "2019-10-28T22:50:12.362905",
     "exception": false,
     "start_time": "2019-10-28T22:50:12.341447",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "objectives = ['Electricity:Facility','DistrictHeating:Facility','DistrictCooling:Facility'] # these get made into `MeterReader` or `VariableReader`\n",
    "\n",
    "problem=EPProblem(parameters, objectives) # problem = parameters + objectives\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "problem.names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Dataset\n",
    "\n",
    "1. Generate 10 samples with sampling strategy\n",
    "2. Setup the parallel processing\n",
    "3. Simulate the Samples\n",
    "4. Store and recover the expensive runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = sampling.dist_sampler(sampling.lhs, problem, num_samples=40)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvaluatorEP(problem, \n",
    "                        building, \n",
    "                        out_dir='outputdir', \n",
    "                        err_dir='outputdir',\n",
    "                        epw_file=epw_file,\n",
    "                        progress_bar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the samples and calculate the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "# Run Energyplus\n",
    "sim_samples = evaluator.df_apply(samples,\n",
    "                             keep_input=True, \n",
    "                             #keep_dirs=True, \n",
    "                             processes=4)  # flag keep_dirs to True to save all ouput\n",
    "t2 = time.time()\n",
    "time_of_sim = t2 - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def niceformat(seconds):\n",
    "    seconds = seconds % (24 * 3600)\n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    return hour, minutes, seconds\n",
    "\n",
    "\n",
    "hours, mins, secs = niceformat(time_of_sim)\n",
    "\n",
    "print(\n",
    "    \"The total running time: {:2.0f} hours {:2.0f} min {:2.0f} seconds\".format(\n",
    "        hours, mins, secs\n",
    "    )\n",
    ")\n",
    "# Build a results DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the expensive calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this can quite a big run. Lets store the results such that we don't have to rerun this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sim_samples.to_pickle(\"simulation_sample_40.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analize and describe your simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_samples = sim_samples.sort_values(by=objectives[1])\n",
    "ax=sim_samples.plot.bar(subplots=True,legend=None, figsize=(12,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018973,
     "end_time": "2019-10-28T23:05:47.372151",
     "exception": false,
     "start_time": "2019-10-28T23:05:47.353178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualising the parametric analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018014,
     "end_time": "2019-10-28T23:05:47.409494",
     "exception": false,
     "start_time": "2019-10-28T23:05:47.391480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A better way to analyse the results is by looking at scatter plots of the inputs versus the outputs.  \n",
    "This enables us to visually see strong relationships of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.070181,
     "end_time": "2019-10-28T23:05:48.497632",
     "exception": false,
     "start_time": "2019-10-28T23:05:47.427451",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "_=pairplot(sim_samples,x_vars=samples.columns, y_vars=objectives, kind=\"scatter\",height=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018711,
     "end_time": "2019-10-28T23:05:48.534391",
     "exception": false,
     "start_time": "2019-10-28T23:05:48.515680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Correlation heat map\n",
    "Another way to analyse the impact of the inputs on the outputs is by analysing the correlation.  \n",
    "A common metric is the Pearsson correlation coefficient:\n",
    "\n",
    "$ r = \\frac{N\\sum{XY}-(\\sum{X}\\sum{Y})}{\\sqrt{ [N\\sum{x^2}-(\\sum{x})^2 ][N\\sum{y^2}-(\\sum{y})^2 }]} $\n",
    "\n",
    "where N is the number of samples. $X$ is the vector of observation of variable 1 (e.g. wall conductivity) and $Y$ is the vetor of observations of variable 2 (e.g. electricity consumption).  \n",
    "The closer $r$ is to one the stronger the correlation, and similarly for negative one and negative correleation.\n",
    "\n",
    "To visualize the correlation coefficients of all inputs and outputs, we can plot a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=sim_samples.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.drop(objectives, axis = 1, inplace = True)\n",
    "corr.drop(['Roof Insulation','Wall Insulation', 'Lights Watts/Area','Ventilation ACH','Temp Setpoint shading', 'Rad Setpoint shading'], axis = 0 ,inplace = True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.217006,
     "end_time": "2019-10-28T23:05:48.772631",
     "exception": false,
     "start_time": "2019-10-28T23:05:48.555625",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize = (13,10))\n",
    "_ = heatmap(corr,annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the dataset for the Surrogate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(samples.columns)\n",
    "print(features)\n",
    "print(objectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove inputs\n",
    "outputs = sim_samples.drop(features, axis=1)\n",
    "#outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outputs and windows types shading\n",
    "samples = sim_samples.drop(objectives, axis=1)\n",
    "#samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,win in enumerate(win_arr):\n",
    "    samples['Windows types'] = samples['Windows types'].replace(win,i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010127,
     "end_time": "2019-10-28T22:51:54.736290",
     "exception": false,
     "start_time": "2019-10-28T22:51:54.726163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train-test split\n",
    "\n",
    "Next we split the data into a training set (80%) and a testing set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.016601,
     "end_time": "2019-10-28T22:51:54.763097",
     "exception": false,
     "start_time": "2019-10-28T22:51:54.746496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_in, test_in, train_out, test_out = train_test_split(\n",
    "    samples, outputs, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011585,
     "end_time": "2019-10-28T22:55:28.550644",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.539059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalization of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010196,
     "end_time": "2019-10-28T22:55:28.572147",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.561951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To ensure an equal weighting of inputs and outputs in the backpropagation algorithm fitting the neural network, we have to normalize the input values.\n",
    "For example window-to-wall ratio is in the range of 0 to 1 while the $W/$m^2$ are in a range of 10 to 15.\n",
    "Different options for normalization exist.\n",
    "Here we bring all features (input variables) to have zero mean and a standarddeviation of 1.\n",
    "Note that we fit the normalizer on training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018939,
     "end_time": "2019-10-28T22:55:28.601090",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.582151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_in_scale = scaler.fit_transform(X=train_in)\n",
    "test_in_scale = scaler.fit_transform(X=test_in)\n",
    "\n",
    "scaler_out = StandardScaler()\n",
    "train_out_scale = scaler_out.fit_transform(X=train_out)\n",
    "test_out_scale = scaler_out.fit_transform(X=test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009287,
     "end_time": "2019-10-28T22:51:54.782132",
     "exception": false,
     "start_time": "2019-10-28T22:51:54.772845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00934,
     "end_time": "2019-10-28T22:51:54.800792",
     "exception": false,
     "start_time": "2019-10-28T22:51:54.791452",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before fitting the GP model we define the set of hyperparameters we want to optimize.\n",
    "Here we use \\textit{3} folds in the k-fold cross validation scheme.\n",
    "We select a set of Kernel functions, which must fit the characteristics of a problem - details and examples may be found in the [Kernel cookbook](https://www.cs.toronto.edu/~duvenaud/cookbook/).\n",
    "Note that the parameters of the Kernel itself are [optimized during each model fitting run](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.015073,
     "end_time": "2019-10-28T22:51:54.825148",
     "exception": false,
     "start_time": "2019-10-28T22:51:54.810075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"kernel\": [\n",
    "        None,\n",
    "        1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0)),\n",
    "        1.0 * RationalQuadratic(length_scale=1.0, alpha=0.5),\n",
    "        # ConstantKernel(0.1, (0.01, 10.0))*(DotProduct(sigma_0=1.0, sigma_0_bounds=(0.1, 10.0))**2),\n",
    "        1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0)),\n",
    "    ]\n",
    "}\n",
    "\n",
    "folds = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010561,
     "end_time": "2019-10-28T22:51:54.846311",
     "exception": false,
     "start_time": "2019-10-28T22:51:54.835750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009632,
     "end_time": "2019-10-28T22:51:54.865875",
     "exception": false,
     "start_time": "2019-10-28T22:51:54.856243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we fit the model using these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     23
    ],
    "papermill": {
     "duration": 0.132473,
     "end_time": "2019-10-28T22:51:55.007586",
     "exception": false,
     "start_time": "2019-10-28T22:51:54.875113",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gp = GaussianProcessRegressor(normalize_y=True)\n",
    "\n",
    "clf = GridSearchCV(gp, hyperparameters, cv=folds)\n",
    "\n",
    "clf.fit(train_in_scale, train_out_scale)\n",
    "\n",
    "best_gp = clf.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_gp = scaler_out.inverse_transform(best_gp.predict(test_in_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013102,
     "end_time": "2019-10-28T22:55:28.626264",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.613162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013102,
     "end_time": "2019-10-28T22:55:28.626264",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.613162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010562,
     "end_time": "2019-10-28T22:55:28.647533",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.636971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before we start fitting the NN model we define the set of hyperparameters we want to analyse in our cross-validation to optimize the model.\n",
    "Here, we select the number of layers of the network as well as the regularization parameter alpha as parameter value.\n",
    "A larger number of layers and a lower value of the regularizer lead to higher variance of the network.\n",
    "This may lead to overfitting.\n",
    "The best selection may be found using an optimizer like Bayesian Optimization.\n",
    "In this example we use a simple grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01634,
     "end_time": "2019-10-28T22:55:28.674195",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.657855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"hidden_layer_sizes\": (\n",
    "        (len(parameters) * 16,),\n",
    "        (len(parameters) * 16, len(parameters) * 16),\n",
    "    ),\n",
    "    \"alpha\": [1, 10, 10 ** 3],\n",
    "}\n",
    "\n",
    "neural_net = MLPRegressor(max_iter=1000, early_stopping=False)\n",
    "folds = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010095,
     "end_time": "2019-10-28T22:55:28.694781",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.684686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010223,
     "end_time": "2019-10-28T22:55:28.715272",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.705049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, we use the NN model from ScikitLearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.458184,
     "end_time": "2019-10-28T22:55:34.184843",
     "exception": false,
     "start_time": "2019-10-28T22:55:28.726659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(neural_net, hyperparameters, cv=folds)\n",
    "clf.fit(train_in_scale, train_out_scale)\n",
    "\n",
    "nn_model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_nn = scaler_out.inverse_transform(nn_model.predict(test_in_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(train_in_scale.shape[1], )),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(3),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\", \"mse\"])\n",
    "    return model\n",
    "\n",
    "tf_model = build_model()\n",
    "\n",
    "tf_model.summary()\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "history = tf_model.fit(\n",
    "    train_in_scale,\n",
    "    train_out_scale,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tf = scaler_out.inverse_transform(tf_model.predict(test_in_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(prediction_gp,test_out.values,multioutput='raw_values',squared=False)/test_out.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_squared_error(prediction_nn,test_out.values,multioutput='raw_values')/test_out.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(prediction_tf,test_out.values,multioutput='raw_values',squared=False)/test_out.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with more samples 20 and 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can load the data from the files in the sim_samples_folder\n",
    "# 20 samples generation took: 5 min 18 seconds\n",
    "# 40 samples generation took: 19 min  7 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010939,
     "end_time": "2019-10-28T22:51:55.029568",
     "exception": false,
     "start_time": "2019-10-28T22:51:55.018629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Surrogate Modelling Evaluator object\n",
    "We can wrap the fitted model in a BESOS `Evaluator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of windows parameters\n",
    "win_arr=[1,2,3]\n",
    "windowsTypes = CategoryParameter(win_arr)\n",
    "\n",
    "windowsParameters = []\n",
    "\n",
    "for fenestration in building.idfobjects[\"FenestrationSurface:Detailed\"]:\n",
    "     if fenestration.obj[2] == \"Window\":\n",
    "        sel = FieldSelector(class_name ='FenestrationSurface:Detailed', object_name = fenestration.Name, field_name='Construction Name' )\n",
    "        windowsParameters.append(Parameter(selector=sel, value_descriptors = windowsTypes, name='Windows types'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = insulation_param + windowsParameters + [lights_param]  + ventilationAchParam + setpointParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objectives and problem definition\n",
    "objectives = ['Electricity:Facility','DistrictHeating:Facility','DistrictCooling:Facility']\n",
    "\n",
    "problem=Problem(parameters, objectives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of the evaluation function\n",
    "def evaluation_func(ind, scaler=scaler):\n",
    "    ind = scaler.transform(X=[ind])\n",
    "    return (scaler_out.inverse_transform(nn_model.predict(ind))[0]).tolist()\n",
    "\n",
    "evaluator = EvaluatorGeneric(evaluation_func, problem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srinputs = sampling.dist_sampler(sampling.lhs, problem, 500)\n",
    "for i,win in enumerate(win_arr):\n",
    "    srinputs['Windows types'] = srinputs['Windows types'].replace(win,i+1)\n",
    "srinputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sroutputs = evaluator.df_apply(srinputs)\n",
    "srresults = srinputs.join(sroutputs)\n",
    "srresults.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.parallel_coordinates(srresults,color=\"Electricity:Facility\", dimensions=features+objectives,\n",
    "                             color_continuous_scale=px.colors.diverging.Tealrose)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Building Optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best surrogate perfomr an otimization process, selct optimal values and save a new idf with the selected values. Evalute the goodnes of the surrogate simuation with EnergyPlus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from besos.optimizer import NSGAII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running NSGA-II optimizator \n",
    "results = NSGAII(evaluator, evaluations=5000, population_size=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optres = results.loc[results[\"pareto-optimal\"] == True, :]  # Get only the optimal results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting results\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(optres, columns=features + objectives)\n",
    "\n",
    "ax.plot3D(results[\"DistrictCooling:Facility\"], results[\"DistrictHeating:Facility\"], results[\"Electricity:Facility\"], \"x\")  # Plot all results in the background as blue crosses\n",
    "ax.plot3D(optres[\"DistrictCooling:Facility\"], optres[\"DistrictHeating:Facility\"], optres[\"Electricity:Facility\"], \"ro\")  # Plot optimal results in red\n",
    "\n",
    "ax.set_xlabel(\"Cooling demand\")\n",
    "ax.set_ylabel(\"Heating demand\")\n",
    "ax.set_zlabel(\"Electricity demand\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_=pairplot(optres,x_vars=samples.columns, y_vars=objectives, kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr=optres.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unuseful = ['violation','pareto-optimal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.drop(objectives + unuseful, axis = 1, inplace = True)\n",
    "corr.drop(features + unuseful, axis = 0 ,inplace = True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,10))\n",
    "_ = heatmap(corr,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total'] = df['Electricity:Facility'] + df['DistrictHeating:Facility'] + df['DistrictCooling:Facility']\n",
    "df['Dist'] = df.apply(lambda row : np.sqrt(pow(row[\"DistrictCooling:Facility\"],2) + pow(row[\"DistrictHeating:Facility\"],2) + pow(row[\"Electricity:Facility\"],2)),axis=1)\n",
    "\n",
    "df[df.Dist == df.Dist.min()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_params=df.loc[df.Dist == df.Dist.min(),features].to_dict('records')[0]\n",
    "optimal_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights_selector.set(building,optimal_params['Lights Watts/Area'])\n",
    "roof_ins.set(building,optimal_params['Roof Insulation'])\n",
    "wall_ins.set(building,optimal_params['Wall Insulation'])\n",
    "shade_setpoint_sel.set(building,optimal_params['Temp Setpoint shading'])\n",
    "shade_setpoint2_sel.set(building,optimal_params['Rad Setpoint shading'])\n",
    "ventACH_sel.set(building,optimal_params['Ventilation ACH'])\n",
    "#selection of windows parameters\n",
    "win_type = 'triple_glazing'\n",
    "for fenestration in building.idfobjects[\"FenestrationSurface:Detailed\"]:\n",
    "     if fenestration.obj[2] == \"Window\":\n",
    "        win_sel = FieldSelector(class_name ='FenestrationSurface:Detailed', \n",
    "                            object_name = fenestration.Name, \n",
    "                            field_name='Construction Name' )\n",
    "        win_sel.set(building,win_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building.saveas('lab_optimal.idf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
